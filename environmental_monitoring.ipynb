{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1f786-231e-4759-9422-b22058e820a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "dataset = datasets.CocoDetection(root='data/coco', transform-transforms.ToTensor())\n",
    "train_size = int(0.8 len(dataset))\n",
    "val_size = len(dataset) train_size\n",
    "train_set, val_set random_split(dataset, [train_size, val_size])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Example: Plotting distribution of object classes\n",
    "object_counts [len([anno for anno in dataset.annotations if anno['category_id'] == cat]) for cat in dataset.categories]\n",
    "plt.bar(range(len(object_counts)), object_counts)\n",
    "plt.xlabel('Object Categories')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose ([ transforms.Resize((256, 256)), transforms.RandomHorizontalFlip(), transforms. RandomRotation(15), transforms. ToTensor(), transforms. Normalize((0.5,), (0.5,)) # example normalization\n",
    "1)\n",
    "# Applying transformation to dataset\n",
    "train_set datasets.CocoDetection (root='data/coco', transform-transform)\n",
    "\n",
    "import torch from torchvision.models import detection\n",
    "# Load a pre-trained YOLOVS model model torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# Define a function to detect objects\n",
    "def detect_objects(image):\n",
    "results = model (image)\n",
    "return results.pandas().xyxy[0] # Get bounding box predictions\n",
    "# Example of model inference\n",
    "image_path = 'path/to/satellite/image.jpg'\n",
    "results detect_objects(image_path)\n",
    "print(results[['name', 'confidence', 'xmin', 'ymin', xmax', \"ymax']])\n",
    "\n",
    "from ultralytics import YOLO\n",
    "#Initialize the YOLOv5 model model = YOLO('yolov5s.pt') # Using the small YOLOVS model variant for faster training\n",
    "# Define training parameters model.train(data='data.yaml', epochs-50, batch_size=16, img_size=640)\n",
    "# Monitor performance metrics through training and validation phases\n",
    "\n",
    "# Example for evaluation\n",
    "metrics = model.val()\n",
    "print(f\"mAP: (metrics['mAP']), Precision: (metrics['Precision']], Recall: (metrics['Recall']}\")\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "#Load YOLOv5 model\n",
    "model torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "# Load and process an image\n",
    "image = Image.open('path/to/satellite_image.jpg')\n",
    "results model(image)\n",
    "# Display detection results with bounding boxes\n",
    "results.show()\n",
    "print(results.pandas().xyxy [0] [['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa238-9d96-481a-a851-4b6878877058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
